{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in /Users/jennamurphy/anaconda3/lib/python3.8/site-packages (0.0)\r\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /Users/jennamurphy/anaconda3/lib/python3.8/site-packages (from sklearn) (0.23.2)\r\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/jennamurphy/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (0.17.0)\r\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /Users/jennamurphy/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\r\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /Users/jennamurphy/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.5.2)\r\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Users/jennamurphy/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies to Visualize the model\n",
    "%matplotlib inline\n",
    "from IPython.display import Image, SVG\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Filepaths, numpy, and Tensorflow\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Sklearn scaling\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Keras Specific Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading and Preprocessing our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Load the MNIST Handwriting Dataset from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Info\n",
      "Training Data Shape: (60000, 28, 28)\n",
      "Training Data Labels Shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(\"Training Data Info\")\n",
    "print(\"Training Data Shape:\", X_train.shape)\n",
    "print(\"Training Data Labels Shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Plot the first digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe2c09c1d90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the first image from the dataset\n",
    "plt.imshow(X_train[0,:,:], cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Each Image is a 28x28 Pixel greyscale image with values from 0 to 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our image is an array of pixels ranging from 0 to 255\n",
    "X_train[0, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### For training a model, we want to flatten our data into rows of 1D image arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: (60000, 784)\n",
      "Testing Shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# We want to flatten our image of 28x28 pixels to a 1D array of 784 pixels\n",
    "ndims = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], ndims)\n",
    "X_test = X_test.reshape(X_test.shape[0], ndims)\n",
    "print(\"Training Shape:\", X_train.shape)\n",
    "print(\"Testing Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scaling and Normalization\n",
    "\n",
    "We use Sklearn's MinMaxScaler to normalize our data between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Next, we normalize our training data to be between 0 and 1\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# Alternative way to normalize this dataset since we know that the max pixel value is 255\n",
    "# X_train = X_train.astype(\"float32\")\n",
    "# X_test = X_test.astype(\"float32\")\n",
    "# X_train /= 255.0\n",
    "# X_test /= 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## One-Hot Encoding\n",
    "\n",
    "We need to one-hot encode our integer labels using the `to_categorical` helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our Training and Testing labels are integer encoded from 0 to 9\n",
    "y_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to convert our target labels (expected values) to categorical data\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "# Original label of `5` is one-hot encoded as `0000010000`\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building our Model\n",
    "\n",
    "In this example, we are going to build a Deep Multi-Layer Perceptron model with 2 hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our first step is to create an empty sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create an empty sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Next, we add our first hidden layer\n",
    "\n",
    "In the first hidden layer, we must also specify the dimension of our input layer. This will simply be the number of elements (pixels) in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Add the first layer where the input dimensions are the 784 pixel values\n",
    "# We can also choose our activation function. `relu` is a common\n",
    "model.add(Dense(100, activation='relu', input_dim=X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## We then add a second hidden layer with 100 densely connected nodes\n",
    "\n",
    "A dense layer is when every node from the previous layer is connected to each node in the current layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Add a second hidden layer\n",
    "model.add(Dense(100, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our final output layer uses a `softmax` activation function for logistic regression.\n",
    "\n",
    "We also need to specify the number of output classes. In this case, the number of digits that we wish to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Add our final output layer where the number of nodes \n",
    "# corresponds to the number of y labels\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We can summarize our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compile and Train our Model\n",
    "\n",
    "Now that we have our model architecture defined, we must compile the model using a loss function and optimizer. We can also specify additional training metrics such as accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Use categorical crossentropy for categorical data and mean squared error for regression\n",
    "# Hint: your output layer in this example is using software for logistic regression (categorical)\n",
    "# If your output layer activation was `linear` then you may want to use `mse` for loss\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Finally, we train our model using our training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Training consists of updating our weights using our optimizer and loss function. In this example, we choose 10 iterations (loops) of training that are called epochs.\n",
    "\n",
    "We also choose to shuffle our training data and increase the detail printed out during each training cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 2s - loss: 0.2372 - accuracy: 0.9301\n",
      "Epoch 2/10\n",
      "1875/1875 - 1s - loss: 0.1015 - accuracy: 0.9687\n",
      "Epoch 3/10\n",
      "1875/1875 - 1s - loss: 0.0707 - accuracy: 0.9786\n",
      "Epoch 4/10\n",
      "1875/1875 - 1s - loss: 0.0557 - accuracy: 0.9819\n",
      "Epoch 5/10\n",
      "1875/1875 - 1s - loss: 0.0454 - accuracy: 0.9855\n",
      "Epoch 6/10\n",
      "1875/1875 - 1s - loss: 0.0349 - accuracy: 0.9885\n",
      "Epoch 7/10\n",
      "1875/1875 - 1s - loss: 0.0301 - accuracy: 0.9901\n",
      "Epoch 8/10\n",
      "1875/1875 - 1s - loss: 0.0260 - accuracy: 0.9908\n",
      "Epoch 9/10\n",
      "1875/1875 - 1s - loss: 0.0218 - accuracy: 0.9926\n",
      "Epoch 10/10\n",
      "1875/1875 - 1s - loss: 0.0219 - accuracy: 0.9927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe2a130fbb0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit (train) the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Saving and Loading models\n",
    "\n",
    "We can save our trained models using the HDF5 binary format with the extension `.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"mnist_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"mnist_trained.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "We use our testing data to validate our model. This is how we determine the validity of our model (i.e. the ability to predict new and previously unseen data points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0955 - accuracy: 0.9779\n",
      "Loss: 0.09548408538103104, Accuracy: 0.9779000282287598\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the training data \n",
    "model_loss, model_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Making Predictions\n",
    "\n",
    "We can use our trained model to make predictions using `model.predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab just one data point to test with\n",
    "test = np.expand_dims(X_train[0], axis=0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe2607504c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOSklEQVR4nO3df4xU9bnH8c8jgqgQg7JQYsnd3kZNjcnd4kiuQQiXegnyDxDsTUlsaCTdxh9JMcRcw02sPxJDzKUVo2myvSD0ptdaBQQTc4sSEkOi1VFRQfydtWxZYYlKhSgt8Nw/9nCz4sx3lpkzc4Z93q9kMzPnOWfP47gfzsx8z5mvubsAjHznFN0AgNYg7EAQhB0IgrADQRB2IIhzW7mziRMnemdnZyt3CYTS29urQ4cOWaVaQ2E3s3mS1kgaJem/3H1Vav3Ozk6Vy+VGdgkgoVQqVa3V/TLezEZJelTSDZKulLTEzK6s9/cBaK5G3rNPl/SBu3/k7n+T9HtJC/JpC0DeGgn7pZL2DXncly37GjPrNrOymZUHBgYa2B2ARjQS9kofAnzj3Ft373H3kruXOjo6GtgdgEY0EvY+SVOHPP62pP2NtQOgWRoJ+yuSLjOz75jZGEk/krQ1n7YA5K3uoTd3P25mt0v6owaH3ta5+57cOgOQq4bG2d39WUnP5tQLgCbidFkgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCaGgWV7S/kydPJuvHjh1r6v43bNhQtXb06NHktm+//Xay/tBDDyXrK1eurFp75JFHktuef/75yfrq1auT9VtuuSVZL0JDYTezXklfSDoh6bi7l/JoCkD+8jiy/4u7H8rh9wBoIt6zA0E0GnaXtM3MXjWz7kormFm3mZXNrDwwMNDg7gDUq9Gwz3D3aZJukHSbmc06fQV373H3kruXOjo6GtwdgHo1FHZ335/dHpS0WdL0PJoCkL+6w25mF5rZ+FP3Jc2VtDuvxgDkq5FP4ydL2mxmp37P/7j7/+bS1Qhz+PDhZP3EiRPJ+htvvJGsb9u2rWrt888/T27b09OTrBeps7MzWV+xYkWyvnbt2qq1iy66KLntzJkzk/U5c+Yk6+2o7rC7+0eS/inHXgA0EUNvQBCEHQiCsANBEHYgCMIOBMElrjno6+tL1ru6upL1zz77LMduzh7nnJM+1qSGzqTal6EuW7asam3SpEnJbceNG5esn41ng3JkB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgGGfPwSWXXJKsT548OVlv53H2uXPnJuu1/ts3bdpUtXbeeeclt509e3ayjjPDkR0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgmCcPQe1rqtev359sv7UU08l69dee22yvnjx4mQ95brrrkvWt2zZkqyPGTMmWf/kk0+q1tasWZPcFvniyA4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQZi7t2xnpVLJy+Vyy/Z3tjh27FiyXmsse+XKlVVrDz74YHLbHTt2JOuzZs1K1tFeSqWSyuWyVarVPLKb2TozO2hmu4csu9jMnjOz97PbCXk2DCB/w3kZv17SvNOW3SVpu7tfJml79hhAG6sZdnd/QdKnpy1eIGlDdn+DpIX5tgUgb/V+QDfZ3fslKbutOnGWmXWbWdnMygMDA3XuDkCjmv5pvLv3uHvJ3Utn42R4wEhRb9gPmNkUScpuD+bXEoBmqDfsWyUtze4vlZS+DhJA4Wpez25mj0uaLWmimfVJ+oWkVZL+YGbLJP1Z0g+b2eRIV+v702uZMKH+kc+HH344WZ85c2ayblZxSBdtqGbY3X1JldIPcu4FQBNxuiwQBGEHgiDsQBCEHQiCsANB8FXSI8Dy5cur1l5++eXktps3b07W9+zZk6xfddVVyTraB0d2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCcfYRIPVV0z09Pcltt2/fnqwvWLAgWV+4cGGyPmPGjKq1RYsWJbfl8tl8cWQHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSCYsjm4Wte7z5t3+pyeX3f48OG6971u3bpkffHixcn6uHHj6t73SNXQlM0ARgbCDgRB2IEgCDsQBGEHgiDsQBCEHQiC69mDmz59erJe63vj77jjjmT9ySefrFq7+eabk9t++OGHyfqdd96ZrI8fPz5Zj6bmkd3M1pnZQTPbPWTZPWb2FzPblf3Mb26bABo1nJfx6yVVOo3qV+7elf08m29bAPJWM+zu/oKkT1vQC4AmauQDutvN7M3sZf6EaiuZWbeZlc2sPDAw0MDuADSi3rD/WtJ3JXVJ6pe0utqK7t7j7iV3L3V0dNS5OwCNqivs7n7A3U+4+0lJv5GU/kgXQOHqCruZTRnycJGk3dXWBdAeal7PbmaPS5otaaKkA5J+kT3ukuSSeiX9zN37a+2M69lHnq+++ipZf+mll6rWrr/++uS2tf42b7zxxmT9iSeeSNZHotT17DVPqnH3JRUWr224KwAtxemyQBCEHQiCsANBEHYgCMIOBMElrmjI2LFjk/XZs2dXrY0aNSq57fHjx5P1p59+Oll/9913q9auuOKK5LYjEUd2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCcXYk7d+/P1nftGlTsv7iiy9WrdUaR6/lmmuuSdYvv/zyhn7/SMORHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCYJx9hKs15dajjz6arD/22GPJel9f3xn3NFy1rnfv7OxM1s0qfqNyWBzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIxtnPAkeOHEnWn3nmmaq1++67L7nte++9V1dPeZgzZ06yvmrVqmT96quvzrOdEa/mkd3MpprZDjPba2Z7zOzn2fKLzew5M3s/u53Q/HYB1Gs4L+OPS1rh7t+T9M+SbjOzKyXdJWm7u18maXv2GECbqhl2d+9399ey+19I2ivpUkkLJG3IVtsgaWGTegSQgzP6gM7MOiV9X9KfJE12935p8B8ESZOqbNNtZmUzK9c6TxtA8ww77GY2TtJGScvd/a/D3c7de9y95O6ljo6OenoEkINhhd3MRmsw6L9z91NfJ3rAzKZk9SmSDjanRQB5qDn0ZoPXCa6VtNfdfzmktFXSUkmrststTelwBDh69Giyvm/fvmT9pptuStZff/31M+4pL3Pnzk3W77333qq1Wl8FzSWq+RrOOPsMST+W9JaZ7cqWrdRgyP9gZssk/VnSD5vSIYBc1Ay7u++UVO2f2B/k2w6AZuF0WSAIwg4EQdiBIAg7EARhB4LgEtdh+vLLL6vWli9fntx2586dyfo777xTT0u5mD9/frJ+9913J+tdXV3J+ujRo8+0JTQJR3YgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCCLMOHtvb2+y/sADDyTrzz//fNXaxx9/XE9Lubnggguq1u6///7ktrfeemuyPmbMmLp6QvvhyA4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQYQZZ9+4cWOyvnbt2qbte9q0acn6kiVLkvVzz03/b+ru7q5aGzt2bHJbxMGRHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCMHdPr2A2VdJvJX1L0klJPe6+xszukfRTSQPZqivd/dnU7yqVSl4ulxtuGkBlpVJJ5XK54qzLwzmp5rikFe7+mpmNl/SqmT2X1X7l7v+ZV6MAmmc487P3S+rP7n9hZnslXdrsxgDk64zes5tZp6TvS/pTtuh2M3vTzNaZ2YQq23SbWdnMygMDA5VWAdACww67mY2TtFHScnf/q6RfS/qupC4NHvlXV9rO3XvcveTupY6OjsY7BlCXYYXdzEZrMOi/c/dNkuTuB9z9hLuflPQbSdOb1yaARtUMu5mZpLWS9rr7L4csnzJktUWSduffHoC8DOfT+BmSfizpLTPblS1bKWmJmXVJckm9kn7WhP4A5GQ4n8bvlFRp3C45pg6gvXAGHRAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IIiaXyWd687MBiR9PGTRREmHWtbAmWnX3tq1L4ne6pVnb//g7hW//62lYf/Gzs3K7l4qrIGEdu2tXfuS6K1ereqNl/FAEIQdCKLosPcUvP+Udu2tXfuS6K1eLemt0PfsAFqn6CM7gBYh7EAQhYTdzOaZ2btm9oGZ3VVED9WYWa+ZvWVmu8ys0Pmlszn0DprZ7iHLLjaz58zs/ey24hx7BfV2j5n9JXvudpnZ/IJ6m2pmO8xsr5ntMbOfZ8sLfe4SfbXkeWv5e3YzGyXpPUn/KqlP0iuSlrj72y1tpAoz65VUcvfCT8Aws1mSjkj6rbtflS17UNKn7r4q+4dygrv/e5v0do+kI0VP453NVjRl6DTjkhZK+okKfO4Sff2bWvC8FXFkny7pA3f/yN3/Jun3khYU0Efbc/cXJH162uIFkjZk9zdo8I+l5ar01hbcvd/dX8vufyHp1DTjhT53ib5aooiwXypp35DHfWqv+d5d0jYze9XMuotupoLJ7t4vDf7xSJpUcD+nqzmNdyudNs142zx39Ux/3qgiwl5pKql2Gv+b4e7TJN0g6bbs5SqGZ1jTeLdKhWnG20K90583qoiw90maOuTxtyXtL6CPitx9f3Z7UNJmtd9U1AdOzaCb3R4suJ//107TeFeaZlxt8NwVOf15EWF/RdJlZvYdMxsj6UeSthbQxzeY2YXZBycyswslzVX7TUW9VdLS7P5SSVsK7OVr2mUa72rTjKvg567w6c/dveU/kuZr8BP5DyX9RxE9VOnrHyW9kf3sKbo3SY9r8GXd3zX4imiZpEskbZf0fnZ7cRv19t+S3pL0pgaDNaWg3q7T4FvDNyXtyn7mF/3cJfpqyfPG6bJAEJxBBwRB2IEgCDsQBGEHgiDsQBCEHQiCsANB/B/B/E1sUrHmQgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(scaler.inverse_transform(test).reshape(28, 28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a prediction. The result should be 0000010000000 for a 5\n",
    "model.predict(test).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab just one data point to test with\n",
    "test = np.expand_dims(X_train[2], axis=0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe2b52425b0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(scaler.inverse_transform(test).reshape(28, 28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot-Encoded Prediction: [[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-1b73e6542c2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Make a prediction. The resulting class should match the digit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"One-Hot-Encoded Prediction: {model.predict(test).round()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Predicted class: {model.predict_classes(test)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "# Make a prediction. The resulting class should match the digit\n",
    "print(f\"One-Hot-Encoded Prediction: {model.predict(test).round()}\")\n",
    "print(f\"Predicted class: {model.predict_classes(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import a Custom Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../Images/test8.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Images/test8.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-92606160dbb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"grayscale\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    311\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupported\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m   \"\"\"\n\u001b[0;32m--> 313\u001b[0;31m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0m\u001b[1;32m    314\u001b[0m                         target_size=target_size, interpolation=interpolation)\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Images/test8.png'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "image_size = (28, 28)\n",
    "im = image.load_img(filepath, target_size=image_size, color_mode=\"grayscale\")\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the image to a numpy array \n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image = img_to_array(im)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the image pixels by 255 (or use a scaler from sklearn here)\n",
    "image /= 255\n",
    "\n",
    "# Flatten into a 1x28*28 array \n",
    "img = image.flatten().reshape(-1, 28*28)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9542ec4eb0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9500e8dd00>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Invert the pixel values to match the original data\n",
    "img = 1 - img\n",
    "plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-e5f4eefd32d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "img = 1 - data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-642f4f96dc11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
